{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "data_path = r'../data'\n",
    "data_file = os.path.join(data_path, 'train.csv')\n",
    "\n",
    "df = pd.read_csv(data_file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional:\n",
      "\n",
      "major\n",
      "0    0.633909\n",
      "1    0.366091\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "conditional:\n",
      "\n",
      "vote_average_binned\n",
      "bad      0.071316\n",
      "great    0.197612\n",
      "ok       0.731071\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "conditional:\n",
      "\n",
      "major  macro_genre\n",
      "0      action         0.357107\n",
      "       dark           0.262506\n",
      "       light          0.281823\n",
      "       other          0.098564\n",
      "1      action         0.451973\n",
      "       dark           0.210978\n",
      "       light          0.273585\n",
      "       other          0.063465\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "conditional:\n",
      "\n",
      "major  us\n",
      "0      0     0.129767\n",
      "       1     0.870233\n",
      "1      0     0.030875\n",
      "       1     0.969125\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "conditional:\n",
      "\n",
      "budget_binned  cast_popularity_binned\n",
      "avg            1st                       0.974359\n",
      "               2nd                       0.025641\n",
      "               3rd                       0.000000\n",
      "high           1st                       0.851636\n",
      "               2nd                       0.139019\n",
      "               3rd                       0.009346\n",
      "low            1st                       0.994798\n",
      "               2nd                       0.003901\n",
      "               3rd                       0.001300\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "conditional:\n",
      "\n",
      "major  macro_genre  budget_binned\n",
      "0      action       avg              0.461859\n",
      "                    high             0.325936\n",
      "                    low              0.212205\n",
      "       dark         avg              0.543396\n",
      "                    high             0.101887\n",
      "                    low              0.354717\n",
      "       light        avg              0.553603\n",
      "                    high             0.121265\n",
      "                    low              0.325132\n",
      "       other        avg              0.462312\n",
      "                    high             0.050251\n",
      "                    low              0.487437\n",
      "1      action       avg              0.371917\n",
      "                    high             0.557875\n",
      "                    low              0.070209\n",
      "       dark         avg              0.487805\n",
      "                    high             0.268293\n",
      "                    low              0.243902\n",
      "       light        avg              0.545455\n",
      "                    high             0.344828\n",
      "                    low              0.109718\n",
      "       other        avg              0.567568\n",
      "                    high             0.243243\n",
      "                    low              0.189189\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    major,\n",
    "    vote_avg,\n",
    "    genre|major,\n",
    "    us|major,\n",
    "    cast_popularity|budget,\n",
    "    budget|major,genre\n",
    "    vote_count_community|movie_popularity\n",
    "    vote_count_critics|movie_popularity\n",
    "    revenue|movie_popularity\n",
    "    \n",
    "    this we don't have:\n",
    "        movie_popularity|genre, us, cast_popularity, vote_avg_community, vote_avg_critics\n",
    "\"\"\"\n",
    "groups = [\n",
    "    df.groupby('major'),\n",
    "    df.groupby('vote_average_binned'),\n",
    "    df.groupby(['major', 'macro_genre']),\n",
    "    df.groupby(['major', 'us']),\n",
    "    df.groupby(['budget_binned', 'cast_popularity_binned']),\n",
    "    df.groupby(['major', 'macro_genre', 'budget_binned'])\n",
    "]\n",
    "\n",
    "# we don't have this, we want to make inference about it\n",
    "#moviepop_groupby = df.groupby(['macro_genre', 'us', 'cast_popularity_category', 'vote_average_category'])\n",
    "\n",
    "# compute the cpt for each group. \n",
    "# Each row in the grouping is a combination for the conditioning vars, with the last column being conditioned.\n",
    "for g in groups:\n",
    "    # Retrieve counts for each grouping \n",
    "    group_count = g.size()\n",
    "    names = group_count.index.names\n",
    "    \n",
    "    # see https://stackoverflow.com/questions/42854801/including-missing-combinations-of-values-in-a-pandas-groupby-aggregation\n",
    "    # we need to unstack each and every level to account for 0-count subgroups\n",
    "    # First unstack every subgroup and substitute missing values with 0, then put everything back.\n",
    "    for lvl in range(1, len(names)):\n",
    "        group_count = group_count.unstack(fill_value=0)\n",
    "        \n",
    "    for lvl in range(1, len(names)):\n",
    "        group_count = group_count.stack()\n",
    "        \n",
    "    if(len(names) > 1):\n",
    "        # group by all but the last column (the one we're conditioning on). Compute probabilities as the ratio\n",
    "        # of the subgroup count/the total for the previous group\n",
    "        levels = list(range(0, len(names)-1))\n",
    "        conditional = group_count.groupby(level=levels).apply(lambda subg: subg/subg.sum())\n",
    "#         joint = group_count/len(df)\n",
    "        filename = '%s-%s.csv' % (names[-1], ','.join(names[0:-1]))\n",
    "    else:\n",
    "        conditional = group_count/group_count.sum()\n",
    "#         joint = conditional\n",
    "        filename = '%s.csv' % names[0]\n",
    "        \n",
    "    # Save cpt to csv files. One file per cpt\n",
    "    conditional[isnan(conditional)] = 0\n",
    "    conditional.to_csv(os.path.join(data_path, 'cpt', filename), header=True, encoding='utf-8')\n",
    "        \n",
    "#     print('joint:\\n')\n",
    "#     print(joint)\n",
    "    print('conditional:\\n')\n",
    "    print(conditional)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
